{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Pollution Tutorial\n",
    "Featured on Jason Brownlee's *Machine Learning Mastery* blog [here](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence TensorFlow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any in {'0', '1', '2'}\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8920\n",
      "drwxr-xr-x  11 jvincen7  MS\\Domain Users   352B Mar  1 10:43 .\n",
      "drwxr-xr-x  11 jvincen7  MS\\Domain Users   352B Mar  1 10:12 ..\n",
      "drwxr-xr-x   3 jvincen7  MS\\Domain Users    96B Mar  1 10:31 .ipynb_checkpoints\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users   1.9K Mar  1 10:29 csv_builder.ipynb\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users   676B Mar  1 10:08 csv_builder.py\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users   149K Mar  1 10:29 data_eda.ipynb\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users   470B Feb  8  2018 data_eda.py\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users    37K Mar  1 10:43 lstm_data_prep.ipynb\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users   3.4K Jun  6  2018 lstm_data_prep.py\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users   2.2M Mar  1 10:08 pollution.csv\n",
      "-rw-r--r--   1 jvincen7  MS\\Domain Users   1.9M Feb  8  2018 raw.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# os.chdir('../')\n",
    "dataset = read_csv('./pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "2   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "3   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "4   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "5   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "\n",
       "   var7(t-1)  var8(t-1)   var1(t)  \n",
       "1   0.000000        0.0  0.148893  \n",
       "2   0.000000        0.0  0.159960  \n",
       "3   0.000000        0.0  0.182093  \n",
       "4   0.037037        0.0  0.138833  \n",
       "5   0.074074        0.0  0.109658  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "\n",
    "reframed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26280, 1, 8) (26280,) (17519, 1, 8) (17519,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "# Using n_train_hours, we are only training on the first 3 years of data (365*24*3), and evaluating on the other 1\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24 * 3\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26280 samples, validate on 17519 samples\n",
      "Epoch 1/50\n",
      "26280/26280 [==============================] - 3s 122us/step - loss: 0.0420 - val_loss: 0.0608\n",
      "Epoch 2/50\n",
      "26280/26280 [==============================] - 4s 134us/step - loss: 0.0181 - val_loss: 0.0294\n",
      "Epoch 3/50\n",
      "26280/26280 [==============================] - 4s 139us/step - loss: 0.0151 - val_loss: 0.0192\n",
      "Epoch 4/50\n",
      "26280/26280 [==============================] - 3s 104us/step - loss: 0.0140 - val_loss: 0.0149\n",
      "Epoch 5/50\n",
      "26280/26280 [==============================] - 3s 125us/step - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 6/50\n",
      "26280/26280 [==============================] - 3s 110us/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 7/50\n",
      "26280/26280 [==============================] - 2s 89us/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 8/50\n",
      "26280/26280 [==============================] - 2s 90us/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 9/50\n",
      "26280/26280 [==============================] - 2s 91us/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 10/50\n",
      "26280/26280 [==============================] - 2s 91us/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 11/50\n",
      "26280/26280 [==============================] - 3s 122us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 12/50\n",
      "26280/26280 [==============================] - 4s 155us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 13/50\n",
      "26280/26280 [==============================] - 3s 112us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 14/50\n",
      "26280/26280 [==============================] - 3s 115us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 15/50\n",
      "26280/26280 [==============================] - 3s 112us/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 16/50\n",
      "26280/26280 [==============================] - 3s 115us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 17/50\n",
      "26280/26280 [==============================] - 3s 113us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 18/50\n",
      "26280/26280 [==============================] - 3s 113us/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 19/50\n",
      "26280/26280 [==============================] - 4s 139us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 20/50\n",
      "26280/26280 [==============================] - 2s 83us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 21/50\n",
      "26280/26280 [==============================] - 3s 107us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 22/50\n",
      "26280/26280 [==============================] - 3s 102us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 23/50\n",
      "26280/26280 [==============================] - 4s 137us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 24/50\n",
      "26280/26280 [==============================] - 3s 118us/step - loss: 0.0136 - val_loss: 0.0142\n",
      "Epoch 25/50\n",
      "26280/26280 [==============================] - 4s 165us/step - loss: 0.0137 - val_loss: 0.0143\n",
      "Epoch 26/50\n",
      "26280/26280 [==============================] - 4s 161us/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 27/50\n",
      "26280/26280 [==============================] - 4s 164us/step - loss: 0.0136 - val_loss: 0.0143\n",
      "Epoch 28/50\n",
      "26280/26280 [==============================] - 3s 125us/step - loss: 0.0136 - val_loss: 0.0140\n",
      "Epoch 29/50\n",
      "26280/26280 [==============================] - 4s 142us/step - loss: 0.0135 - val_loss: 0.0140\n",
      "Epoch 30/50\n",
      "26280/26280 [==============================] - 4s 149us/step - loss: 0.0136 - val_loss: 0.0141\n",
      "Epoch 31/50\n",
      "26280/26280 [==============================] - 2s 93us/step - loss: 0.0136 - val_loss: 0.0139\n",
      "Epoch 32/50\n",
      "26280/26280 [==============================] - 2s 88us/step - loss: 0.0136 - val_loss: 0.0140\n",
      "Epoch 33/50\n",
      "26280/26280 [==============================] - 3s 100us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 34/50\n",
      "26280/26280 [==============================] - 4s 143us/step - loss: 0.0136 - val_loss: 0.0139\n",
      "Epoch 35/50\n",
      "26280/26280 [==============================] - 5s 174us/step - loss: 0.0136 - val_loss: 0.0140\n",
      "Epoch 36/50\n",
      "26280/26280 [==============================] - 3s 127us/step - loss: 0.0136 - val_loss: 0.0137\n",
      "Epoch 37/50\n",
      "26280/26280 [==============================] - 3s 130us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 38/50\n",
      "26280/26280 [==============================] - 3s 116us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 39/50\n",
      "26280/26280 [==============================] - 3s 128us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 40/50\n",
      "26280/26280 [==============================] - 4s 134us/step - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 41/50\n",
      "26280/26280 [==============================] - 3s 130us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 42/50\n",
      "26280/26280 [==============================] - 3s 129us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 43/50\n",
      "26280/26280 [==============================] - 4s 135us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 44/50\n",
      "26280/26280 [==============================] - 3s 106us/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 45/50\n",
      "26280/26280 [==============================] - 3s 99us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 46/50\n",
      "26280/26280 [==============================] - 3s 121us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 47/50\n",
      "26280/26280 [==============================] - 3s 121us/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 48/50\n",
      "26280/26280 [==============================] - 3s 127us/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 49/50\n",
      "26280/26280 [==============================] - 3s 130us/step - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 50/50\n",
      "26280/26280 [==============================] - 3s 131us/step - loss: 0.0135 - val_loss: 0.0137\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"38133f67-ccb1-4d60-87fa-0a1f90bfa87a\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"38133f67-ccb1-4d60-87fa-0a1f90bfa87a\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2d0e8b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 26.730\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
