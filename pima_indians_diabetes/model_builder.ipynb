{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima Indians Diabetes Tutorial\n",
    "Feauted on Jason Brownlee's *Machine Learning Mastery* blog [here](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter path to dataset: ./pima-indians-diabetes.csv\n"
     ]
    }
   ],
   "source": [
    "# Fix random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset\n",
    "path = str(input('Enter path to dataset: '))\n",
    "dataset = np.loadtxt(path, delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the proportion of data (as a decimal) to use as the training set: 0.85\n",
      "Enter the proportion of data (as a decimal) to use as the test set: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "train = float(input('Enter the proportion of data (as a decimal) to use as the training set: '))\n",
    "test = float(input('Enter the proportion of data (as a decimal) to use as the test set: '))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test,\\\n",
    " train_size = train, random_state = 42)\n",
    "np.savetxt('X_train.csv', X_train, delimiter = ',')\n",
    "np.savetxt('X_test.csv', X_test, delimiter = ',')\n",
    "np.savetxt('y_train.csv', y_train, delimiter = ',')\n",
    "np.savetxt('y_test.csv', y_test, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "#model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(200, activation = 'tanh'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "652/652 [==============================] - 0s 707us/step - loss: 0.6426 - acc: 0.6258\n",
      "Epoch 2/150\n",
      "652/652 [==============================] - 0s 513us/step - loss: 0.6345 - acc: 0.6442\n",
      "Epoch 3/150\n",
      "652/652 [==============================] - 0s 605us/step - loss: 0.6181 - acc: 0.6610\n",
      "Epoch 4/150\n",
      "652/652 [==============================] - 0s 562us/step - loss: 0.5986 - acc: 0.6641\n",
      "Epoch 5/150\n",
      "652/652 [==============================] - 0s 583us/step - loss: 0.6025 - acc: 0.6887\n",
      "Epoch 6/150\n",
      "652/652 [==============================] - 0s 523us/step - loss: 0.5941 - acc: 0.6748\n",
      "Epoch 7/150\n",
      "652/652 [==============================] - 0s 500us/step - loss: 0.6059 - acc: 0.6733\n",
      "Epoch 8/150\n",
      "652/652 [==============================] - 0s 497us/step - loss: 0.5939 - acc: 0.6610\n",
      "Epoch 9/150\n",
      "652/652 [==============================] - 0s 530us/step - loss: 0.5903 - acc: 0.6764\n",
      "Epoch 10/150\n",
      "652/652 [==============================] - 0s 517us/step - loss: 0.6161 - acc: 0.6656\n",
      "Epoch 11/150\n",
      "652/652 [==============================] - 0s 536us/step - loss: 0.5832 - acc: 0.6825\n",
      "Epoch 12/150\n",
      "652/652 [==============================] - 0s 520us/step - loss: 0.5834 - acc: 0.6810\n",
      "Epoch 13/150\n",
      "652/652 [==============================] - 0s 520us/step - loss: 0.5980 - acc: 0.6672\n",
      "Epoch 14/150\n",
      "652/652 [==============================] - 0s 522us/step - loss: 0.5842 - acc: 0.6917\n",
      "Epoch 15/150\n",
      "652/652 [==============================] - 0s 509us/step - loss: 0.5784 - acc: 0.6748\n",
      "Epoch 16/150\n",
      "652/652 [==============================] - 0s 507us/step - loss: 0.5839 - acc: 0.6580\n",
      "Epoch 17/150\n",
      "652/652 [==============================] - 0s 531us/step - loss: 0.5866 - acc: 0.6687\n",
      "Epoch 18/150\n",
      "652/652 [==============================] - 0s 540us/step - loss: 0.5822 - acc: 0.6534\n",
      "Epoch 19/150\n",
      "652/652 [==============================] - 0s 507us/step - loss: 0.5886 - acc: 0.6702\n",
      "Epoch 20/150\n",
      "652/652 [==============================] - 0s 508us/step - loss: 0.5792 - acc: 0.6718\n",
      "Epoch 21/150\n",
      "652/652 [==============================] - 0s 530us/step - loss: 0.5630 - acc: 0.6948\n",
      "Epoch 22/150\n",
      "652/652 [==============================] - 0s 536us/step - loss: 0.5699 - acc: 0.7040\n",
      "Epoch 23/150\n",
      "652/652 [==============================] - 0s 543us/step - loss: 0.5702 - acc: 0.6948\n",
      "Epoch 24/150\n",
      "652/652 [==============================] - 0s 615us/step - loss: 0.5741 - acc: 0.6779\n",
      "Epoch 25/150\n",
      "652/652 [==============================] - 0s 533us/step - loss: 0.5684 - acc: 0.7009\n",
      "Epoch 26/150\n",
      "652/652 [==============================] - 0s 510us/step - loss: 0.5611 - acc: 0.6994\n",
      "Epoch 27/150\n",
      "652/652 [==============================] - 0s 528us/step - loss: 0.5667 - acc: 0.6917\n",
      "Epoch 28/150\n",
      "652/652 [==============================] - 0s 547us/step - loss: 0.5553 - acc: 0.7224\n",
      "Epoch 29/150\n",
      "652/652 [==============================] - 0s 614us/step - loss: 0.5721 - acc: 0.6794\n",
      "Epoch 30/150\n",
      "652/652 [==============================] - 0s 559us/step - loss: 0.5502 - acc: 0.7285\n",
      "Epoch 31/150\n",
      "652/652 [==============================] - 0s 545us/step - loss: 0.5510 - acc: 0.7193\n",
      "Epoch 32/150\n",
      "652/652 [==============================] - 0s 531us/step - loss: 0.5431 - acc: 0.7301\n",
      "Epoch 33/150\n",
      "652/652 [==============================] - 1s 863us/step - loss: 0.5489 - acc: 0.7132\n",
      "Epoch 34/150\n",
      "652/652 [==============================] - 1s 971us/step - loss: 0.5690 - acc: 0.6718\n",
      "Epoch 35/150\n",
      "652/652 [==============================] - 0s 763us/step - loss: 0.5521 - acc: 0.6948\n",
      "Epoch 36/150\n",
      "652/652 [==============================] - 0s 595us/step - loss: 0.5575 - acc: 0.7055\n",
      "Epoch 37/150\n",
      "652/652 [==============================] - 0s 592us/step - loss: 0.5472 - acc: 0.6994\n",
      "Epoch 38/150\n",
      "652/652 [==============================] - 1s 858us/step - loss: 0.5247 - acc: 0.7347\n",
      "Epoch 39/150\n",
      "652/652 [==============================] - 0s 623us/step - loss: 0.5209 - acc: 0.7316\n",
      "Epoch 40/150\n",
      "652/652 [==============================] - 0s 593us/step - loss: 0.5556 - acc: 0.7209\n",
      "Epoch 41/150\n",
      "652/652 [==============================] - 0s 445us/step - loss: 0.5509 - acc: 0.6825\n",
      "Epoch 42/150\n",
      "652/652 [==============================] - 0s 488us/step - loss: 0.5587 - acc: 0.7147\n",
      "Epoch 43/150\n",
      "652/652 [==============================] - 0s 440us/step - loss: 0.5348 - acc: 0.7331\n",
      "Epoch 44/150\n",
      "652/652 [==============================] - 0s 473us/step - loss: 0.5148 - acc: 0.7362\n",
      "Epoch 45/150\n",
      "652/652 [==============================] - 0s 438us/step - loss: 0.5111 - acc: 0.7423\n",
      "Epoch 46/150\n",
      "652/652 [==============================] - 0s 490us/step - loss: 0.5102 - acc: 0.7500\n",
      "Epoch 47/150\n",
      "652/652 [==============================] - 0s 455us/step - loss: 0.5231 - acc: 0.7546\n",
      "Epoch 48/150\n",
      "652/652 [==============================] - 0s 447us/step - loss: 0.5144 - acc: 0.7408\n",
      "Epoch 49/150\n",
      "652/652 [==============================] - 0s 457us/step - loss: 0.5127 - acc: 0.7377\n",
      "Epoch 50/150\n",
      "652/652 [==============================] - 0s 446us/step - loss: 0.4891 - acc: 0.7561\n",
      "Epoch 51/150\n",
      "652/652 [==============================] - 0s 579us/step - loss: 0.5039 - acc: 0.7454\n",
      "Epoch 52/150\n",
      "652/652 [==============================] - 0s 519us/step - loss: 0.4961 - acc: 0.7408\n",
      "Epoch 53/150\n",
      "652/652 [==============================] - 0s 440us/step - loss: 0.5065 - acc: 0.7423\n",
      "Epoch 54/150\n",
      "652/652 [==============================] - 0s 467us/step - loss: 0.5138 - acc: 0.7577\n",
      "Epoch 55/150\n",
      "652/652 [==============================] - 0s 678us/step - loss: 0.5019 - acc: 0.7531\n",
      "Epoch 56/150\n",
      "652/652 [==============================] - 0s 514us/step - loss: 0.4929 - acc: 0.7561\n",
      "Epoch 57/150\n",
      "652/652 [==============================] - 0s 618us/step - loss: 0.4769 - acc: 0.7730\n",
      "Epoch 58/150\n",
      "652/652 [==============================] - 0s 520us/step - loss: 0.4951 - acc: 0.7653\n",
      "Epoch 59/150\n",
      "652/652 [==============================] - 0s 504us/step - loss: 0.4952 - acc: 0.7377\n",
      "Epoch 60/150\n",
      "652/652 [==============================] - 0s 505us/step - loss: 0.4811 - acc: 0.7439\n",
      "Epoch 61/150\n",
      "652/652 [==============================] - 0s 510us/step - loss: 0.4617 - acc: 0.7761\n",
      "Epoch 62/150\n",
      "652/652 [==============================] - 0s 502us/step - loss: 0.4699 - acc: 0.7715\n",
      "Epoch 63/150\n",
      "652/652 [==============================] - 0s 493us/step - loss: 0.4838 - acc: 0.7623\n",
      "Epoch 64/150\n",
      "652/652 [==============================] - 0s 511us/step - loss: 0.4735 - acc: 0.7730\n",
      "Epoch 65/150\n",
      "652/652 [==============================] - 0s 488us/step - loss: 0.4663 - acc: 0.7699\n",
      "Epoch 66/150\n",
      "652/652 [==============================] - 0s 496us/step - loss: 0.4711 - acc: 0.7592\n",
      "Epoch 67/150\n",
      "652/652 [==============================] - 0s 515us/step - loss: 0.4454 - acc: 0.7914\n",
      "Epoch 68/150\n",
      "652/652 [==============================] - 0s 516us/step - loss: 0.4746 - acc: 0.7669\n",
      "Epoch 69/150\n",
      "652/652 [==============================] - 0s 527us/step - loss: 0.4583 - acc: 0.7761\n",
      "Epoch 70/150\n",
      "652/652 [==============================] - 0s 682us/step - loss: 0.4603 - acc: 0.7776\n",
      "Epoch 71/150\n",
      "652/652 [==============================] - 0s 519us/step - loss: 0.4458 - acc: 0.7822\n",
      "Epoch 72/150\n",
      "652/652 [==============================] - 0s 522us/step - loss: 0.4581 - acc: 0.7607\n",
      "Epoch 73/150\n",
      "652/652 [==============================] - 0s 510us/step - loss: 0.4394 - acc: 0.7837\n",
      "Epoch 74/150\n",
      "652/652 [==============================] - 0s 516us/step - loss: 0.4351 - acc: 0.7899\n",
      "Epoch 75/150\n",
      "652/652 [==============================] - 0s 618us/step - loss: 0.4554 - acc: 0.7684\n",
      "Epoch 76/150\n",
      "652/652 [==============================] - 0s 642us/step - loss: 0.4523 - acc: 0.7914\n",
      "Epoch 77/150\n",
      "652/652 [==============================] - 0s 606us/step - loss: 0.4408 - acc: 0.7883\n",
      "Epoch 78/150\n",
      "652/652 [==============================] - 0s 652us/step - loss: 0.4373 - acc: 0.7853\n",
      "Epoch 79/150\n",
      "652/652 [==============================] - 0s 672us/step - loss: 0.4607 - acc: 0.7776\n",
      "Epoch 80/150\n",
      "652/652 [==============================] - 0s 689us/step - loss: 0.4368 - acc: 0.7776\n",
      "Epoch 81/150\n",
      "652/652 [==============================] - 0s 558us/step - loss: 0.4234 - acc: 0.7868\n",
      "Epoch 82/150\n",
      "652/652 [==============================] - 0s 588us/step - loss: 0.4280 - acc: 0.8021\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/652 [==============================] - 0s 555us/step - loss: 0.4376 - acc: 0.7745\n",
      "Epoch 84/150\n",
      "652/652 [==============================] - 0s 535us/step - loss: 0.4485 - acc: 0.7837\n",
      "Epoch 85/150\n",
      "652/652 [==============================] - 0s 597us/step - loss: 0.4170 - acc: 0.8037\n",
      "Epoch 86/150\n",
      "652/652 [==============================] - 0s 553us/step - loss: 0.4483 - acc: 0.7929\n",
      "Epoch 87/150\n",
      "652/652 [==============================] - 0s 513us/step - loss: 0.4239 - acc: 0.8006\n",
      "Epoch 88/150\n",
      "652/652 [==============================] - 0s 558us/step - loss: 0.4429 - acc: 0.7822\n",
      "Epoch 89/150\n",
      "652/652 [==============================] - 0s 553us/step - loss: 0.4272 - acc: 0.8052\n",
      "Epoch 90/150\n",
      "652/652 [==============================] - 0s 515us/step - loss: 0.4134 - acc: 0.7975\n",
      "Epoch 91/150\n",
      "652/652 [==============================] - 0s 543us/step - loss: 0.4238 - acc: 0.8006\n",
      "Epoch 92/150\n",
      "652/652 [==============================] - 0s 523us/step - loss: 0.4065 - acc: 0.8037\n",
      "Epoch 93/150\n",
      "652/652 [==============================] - 0s 521us/step - loss: 0.4101 - acc: 0.8160\n",
      "Epoch 94/150\n",
      "652/652 [==============================] - 0s 497us/step - loss: 0.4137 - acc: 0.8006\n",
      "Epoch 95/150\n",
      "652/652 [==============================] - 0s 600us/step - loss: 0.4062 - acc: 0.8098\n",
      "Epoch 96/150\n",
      "652/652 [==============================] - 0s 539us/step - loss: 0.4305 - acc: 0.7684\n",
      "Epoch 97/150\n",
      "652/652 [==============================] - 0s 536us/step - loss: 0.3995 - acc: 0.8129\n",
      "Epoch 98/150\n",
      "652/652 [==============================] - 0s 528us/step - loss: 0.4476 - acc: 0.7822\n",
      "Epoch 99/150\n",
      "652/652 [==============================] - 0s 516us/step - loss: 0.4135 - acc: 0.7991\n",
      "Epoch 100/150\n",
      "652/652 [==============================] - 0s 521us/step - loss: 0.4079 - acc: 0.7975\n",
      "Epoch 101/150\n",
      "652/652 [==============================] - 0s 509us/step - loss: 0.3967 - acc: 0.7899\n",
      "Epoch 102/150\n",
      "652/652 [==============================] - 0s 547us/step - loss: 0.4050 - acc: 0.8129\n",
      "Epoch 103/150\n",
      "652/652 [==============================] - 0s 532us/step - loss: 0.4114 - acc: 0.7945\n",
      "Epoch 104/150\n",
      "652/652 [==============================] - 0s 533us/step - loss: 0.4179 - acc: 0.7991\n",
      "Epoch 105/150\n",
      "652/652 [==============================] - 0s 505us/step - loss: 0.3953 - acc: 0.7991\n",
      "Epoch 106/150\n",
      "652/652 [==============================] - 0s 540us/step - loss: 0.4280 - acc: 0.7960\n",
      "Epoch 107/150\n",
      "652/652 [==============================] - 0s 506us/step - loss: 0.4163 - acc: 0.7837\n",
      "Epoch 108/150\n",
      "652/652 [==============================] - 0s 525us/step - loss: 0.4120 - acc: 0.7899\n",
      "Epoch 109/150\n",
      "652/652 [==============================] - 0s 538us/step - loss: 0.4050 - acc: 0.7975\n",
      "Epoch 110/150\n",
      "652/652 [==============================] - 0s 549us/step - loss: 0.4046 - acc: 0.7991\n",
      "Epoch 111/150\n",
      "652/652 [==============================] - 0s 592us/step - loss: 0.3917 - acc: 0.8098\n",
      "Epoch 112/150\n",
      "652/652 [==============================] - 0s 539us/step - loss: 0.3829 - acc: 0.8313\n",
      "Epoch 113/150\n",
      "652/652 [==============================] - 0s 514us/step - loss: 0.3909 - acc: 0.8190\n",
      "Epoch 114/150\n",
      "652/652 [==============================] - 0s 515us/step - loss: 0.3768 - acc: 0.8344\n",
      "Epoch 115/150\n",
      "652/652 [==============================] - 0s 522us/step - loss: 0.3818 - acc: 0.8252\n",
      "Epoch 116/150\n",
      "652/652 [==============================] - 0s 503us/step - loss: 0.3851 - acc: 0.8175\n",
      "Epoch 117/150\n",
      "652/652 [==============================] - 0s 497us/step - loss: 0.3912 - acc: 0.8267\n",
      "Epoch 118/150\n",
      "652/652 [==============================] - 0s 475us/step - loss: 0.3671 - acc: 0.8252\n",
      "Epoch 119/150\n",
      "652/652 [==============================] - 0s 512us/step - loss: 0.4049 - acc: 0.8098\n",
      "Epoch 120/150\n",
      "652/652 [==============================] - 0s 510us/step - loss: 0.4023 - acc: 0.8067\n",
      "Epoch 121/150\n",
      "652/652 [==============================] - 0s 533us/step - loss: 0.4033 - acc: 0.8129\n",
      "Epoch 122/150\n",
      "652/652 [==============================] - 0s 547us/step - loss: 0.3948 - acc: 0.8267\n",
      "Epoch 123/150\n",
      "652/652 [==============================] - 0s 503us/step - loss: 0.3655 - acc: 0.8252\n",
      "Epoch 124/150\n",
      "652/652 [==============================] - 0s 509us/step - loss: 0.3641 - acc: 0.8282\n",
      "Epoch 125/150\n",
      "652/652 [==============================] - 0s 529us/step - loss: 0.3672 - acc: 0.8236\n",
      "Epoch 126/150\n",
      "652/652 [==============================] - 0s 545us/step - loss: 0.3799 - acc: 0.8083\n",
      "Epoch 127/150\n",
      "652/652 [==============================] - 0s 535us/step - loss: 0.3816 - acc: 0.8221\n",
      "Epoch 128/150\n",
      "652/652 [==============================] - 0s 537us/step - loss: 0.3604 - acc: 0.8267\n",
      "Epoch 129/150\n",
      "652/652 [==============================] - 0s 512us/step - loss: 0.3913 - acc: 0.8113\n",
      "Epoch 130/150\n",
      "652/652 [==============================] - 0s 501us/step - loss: 0.3896 - acc: 0.8067\n",
      "Epoch 131/150\n",
      "652/652 [==============================] - 0s 505us/step - loss: 0.3850 - acc: 0.8206\n",
      "Epoch 132/150\n",
      "652/652 [==============================] - 0s 514us/step - loss: 0.3810 - acc: 0.8466\n",
      "Epoch 133/150\n",
      "652/652 [==============================] - 0s 526us/step - loss: 0.3485 - acc: 0.8405\n",
      "Epoch 134/150\n",
      "652/652 [==============================] - 0s 511us/step - loss: 0.3586 - acc: 0.8359\n",
      "Epoch 135/150\n",
      "652/652 [==============================] - 0s 495us/step - loss: 0.3781 - acc: 0.8144\n",
      "Epoch 136/150\n",
      "652/652 [==============================] - 0s 518us/step - loss: 0.3728 - acc: 0.8221\n",
      "Epoch 137/150\n",
      "652/652 [==============================] - 0s 528us/step - loss: 0.3637 - acc: 0.8282\n",
      "Epoch 138/150\n",
      "652/652 [==============================] - 0s 505us/step - loss: 0.4007 - acc: 0.8052\n",
      "Epoch 139/150\n",
      "652/652 [==============================] - 0s 525us/step - loss: 0.3551 - acc: 0.8267\n",
      "Epoch 140/150\n",
      "652/652 [==============================] - 0s 502us/step - loss: 0.3602 - acc: 0.8160\n",
      "Epoch 141/150\n",
      "652/652 [==============================] - 0s 506us/step - loss: 0.3748 - acc: 0.8221\n",
      "Epoch 142/150\n",
      "652/652 [==============================] - 0s 507us/step - loss: 0.3550 - acc: 0.8236\n",
      "Epoch 143/150\n",
      "652/652 [==============================] - 0s 533us/step - loss: 0.3461 - acc: 0.8405\n",
      "Epoch 144/150\n",
      "652/652 [==============================] - 0s 521us/step - loss: 0.3999 - acc: 0.8221\n",
      "Epoch 145/150\n",
      "652/652 [==============================] - 0s 522us/step - loss: 0.3714 - acc: 0.8420\n",
      "Epoch 146/150\n",
      "652/652 [==============================] - 0s 510us/step - loss: 0.3745 - acc: 0.8252\n",
      "Epoch 147/150\n",
      "652/652 [==============================] - 0s 485us/step - loss: 0.3508 - acc: 0.8298\n",
      "Epoch 148/150\n",
      "652/652 [==============================] - 0s 512us/step - loss: 0.3617 - acc: 0.8344\n",
      "Epoch 149/150\n",
      "652/652 [==============================] - 0s 521us/step - loss: 0.3419 - acc: 0.8436\n",
      "Epoch 150/150\n",
      "652/652 [==============================] - 0s 519us/step - loss: 0.3732 - acc: 0.8206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1cbe15c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"c49c9032-8a04-4350-b396-8918134c4d31\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"c49c9032-8a04-4350-b396-8918134c4d31\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "# Fit model\n",
    "model.fit(X_train, y_train, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652/652 [==============================] - 0s 120us/step\n",
      "\n",
      "acc: 85.12%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "scores = model.evaluate(X_train, y_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
